{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.8 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 5.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: f7911b23-f526-46ba-a3ff-db1ee77ea30c\nApplying the following default arguments:\n--glue_kernel_version 1.0.8\n--enable-glue-datacatalog true\nWaiting for session f7911b23-f526-46ba-a3ff-db1ee77ea30c to get into ready status...\nSession f7911b23-f526-46ba-a3ff-db1ee77ea30c has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "csv_files = [\n    \"consultas\",\n    \"exames\",\n    \"hospitais\",\n    \"internacoes\",\n    \"procedimentos\",\n    \"profissionais_saude\",\n    \"receitas\"\n]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def gravar_dados_rds(dynamic_frame, table_name, glueContext): \n    glueContext.write_dynamic_frame.from_options(\n        frame=dynamic_frame,\n        connection_type=\"postgresql\",\n        connection_options={\n            \"url\": \"jdbc:postgresql://datahandson-genai-dev-postgres.cnai0csqspw4.us-east-2.rds.amazonaws.com:5432/hospital_database\",\n            \"user\": \"postgres\",\n            \"password\": \"Mds20251\",  # RECOMENDADO: use Secrets Manager no lugar\n            \"dbtable\": f\"public.{table_name}\"\n        },\n        transformation_ctx=\"jdbc_output\"\n    )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "s3_path_raw = 's3://cjmm-mds-lake-raw/hospital_datahandson_csv'\n\nfor table in csv_files:\n    df = spark.read.csv(f\"{s3_path_raw}/{table}.csv\", header=True, inferSchema=True)\n    dynamic_frame = DynamicFrame.fromDF(df, glueContext, \"meu_dynamic_frame_exemplo\")\n    gravar_dados_rds(dynamic_frame, table, glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "NameError: name 's3_path_raw' is not defined\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}